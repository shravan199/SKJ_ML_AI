{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operations on NumPy Arrays\n",
    "\n",
    "The learning objectives of this section are:\n",
    "\n",
    "* Manipulate arrays\n",
    "    * Reshape arrays\n",
    "    * Stack arrays\n",
    "* Perform operations on arrays\n",
    "    * Perform basic mathematical operations\n",
    "    * Apply built-in functions \n",
    "    * Apply your own functions \n",
    "    * Apply basic linear algebra operations \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating Arrays\n",
    "\n",
    "Let's look at some ways to manipulate arrays, i.e. changing the shape, combining and splitting arrays, etc.   \n",
    "\n",
    "#### Reshaping Arrays\n",
    "\n",
    "Reshaping is done using the ```reshape()``` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Reshape a 1-D array to a 3 x 4 array\n",
    "some_array = np.arange(0, 12).reshape(3, 4)\n",
    "print(some_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.84031406, 0.26965811, 0.93470515, 0.23841032, 0.38779949,\n",
       "        0.5290163 ],\n",
       "       [0.30700639, 0.83277247, 0.78702489, 0.80612649, 0.34200263,\n",
       "        0.86437963],\n",
       "       [0.80916323, 0.53974556, 0.58882123, 0.31634349, 0.53091729,\n",
       "        0.20156946],\n",
       "       [0.91843169, 0.3315271 , 0.67847363, 0.47495926, 0.32195073,\n",
       "        0.51234671]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_array = np.random.rand(24).reshape(4,-1)\n",
    "np_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 6)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4,  5],\n",
       "       [ 6,  7,  8,  9, 10, 11]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can reshape it further \n",
    "some_array.reshape(2, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2],\n",
       "       [ 3,  4,  5],\n",
       "       [ 6,  7,  8],\n",
       "       [ 9, 10, 11]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you specify -1 as a dimension, the dimensions are automatically calculated\n",
    "# -1 means \"whatever dimension is needed\" \n",
    "some_array.reshape(4, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```array.T``` returns the transpose of an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  4,  8],\n",
       "       [ 1,  5,  9],\n",
       "       [ 2,  6, 10],\n",
       "       [ 3,  7, 11]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transposing an array\n",
    "some_array.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.84031406, 0.30700639, 0.80916323, 0.91843169],\n",
       "       [0.26965811, 0.83277247, 0.53974556, 0.3315271 ],\n",
       "       [0.93470515, 0.78702489, 0.58882123, 0.67847363],\n",
       "       [0.23841032, 0.80612649, 0.31634349, 0.47495926],\n",
       "       [0.38779949, 0.34200263, 0.53091729, 0.32195073],\n",
       "       [0.5290163 , 0.86437963, 0.20156946, 0.51234671]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_array.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking and Splitting Arrays\n",
    "\n",
    "#### Stacking: ```np.hstack()``` and ```n.vstack()```\n",
    "\n",
    "Stacking is done using the ```np.hstack()``` and ```np.vstack()``` methods. For horizontal stacking, the number of rows should be the same, while for vertical stacking, the number of columns should be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]]\n",
      "\n",
      "\n",
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]\n",
      " [12 13 14 15]\n",
      " [16 17 18 19]]\n"
     ]
    }
   ],
   "source": [
    "# Creating two arrays\n",
    "array_1 = np.arange(12).reshape(3, 4)\n",
    "array_2 = np.arange(20).reshape(5, 4)\n",
    "\n",
    "print(array_1)\n",
    "print(\"\\n\")\n",
    "print(array_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11],\n",
       "       [ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11],\n",
       "       [12, 13, 14, 15],\n",
       "       [16, 17, 18, 19]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vstack\n",
    "# Note that np.vstack(a, b) throws an error - you need to pass the arrays as a list\n",
    "np.vstack((array_1, array_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33112064 0.27949875 0.98047647 0.05222393]\n",
      " [0.80431935 0.59611061 0.9624192  0.81935952]\n",
      " [0.65771846 0.98661731 0.96767623 0.51034578]\n",
      " [0.04164961 0.04851168 0.61549497 0.42007576]\n",
      " [0.43230627 0.46867022 0.97002653 0.47004848]]\n",
      "\n",
      "[[0.93902716 0.89578073 0.31486321 0.2017403 ]\n",
      " [0.69203795 0.96584573 0.27614724 0.44993481]\n",
      " [0.26304609 0.53369815 0.87073121 0.76557653]\n",
      " [0.04980542 0.0718783  0.57557772 0.07912574]\n",
      " [0.90039579 0.00401615 0.96848228 0.70924557]\n",
      " [0.4016378  0.39915533 0.42553754 0.81231506]]\n"
     ]
    }
   ],
   "source": [
    "np_arrays1 = np.random.rand(5,4)\n",
    "np_arrays2= np.random.rand(6, 4)\n",
    "print(np_arrays1)\n",
    "print()\n",
    "print(np_arrays2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33112064, 0.27949875, 0.98047647, 0.05222393],\n",
       "       [0.80431935, 0.59611061, 0.9624192 , 0.81935952],\n",
       "       [0.65771846, 0.98661731, 0.96767623, 0.51034578],\n",
       "       [0.04164961, 0.04851168, 0.61549497, 0.42007576],\n",
       "       [0.43230627, 0.46867022, 0.97002653, 0.47004848],\n",
       "       [0.93902716, 0.89578073, 0.31486321, 0.2017403 ],\n",
       "       [0.69203795, 0.96584573, 0.27614724, 0.44993481],\n",
       "       [0.26304609, 0.53369815, 0.87073121, 0.76557653],\n",
       "       [0.04980542, 0.0718783 , 0.57557772, 0.07912574],\n",
       "       [0.90039579, 0.00401615, 0.96848228, 0.70924557],\n",
       "       [0.4016378 , 0.39915533, 0.42553754, 0.81231506]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_np_array =  np.vstack((np_arrays1, np_arrays2))\n",
    "stacked_np_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, two arrays having the same number of rows can be horizontally stacked using ```np.hstack((a, b))```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.41723231 0.34591743 0.88468288 0.76886988 0.81339919]\n",
      " [0.4974245  0.06467744 0.14562472 0.32918862 0.38522401]\n",
      " [0.69372557 0.36821633 0.47568952 0.29220725 0.96136218]\n",
      " [0.34981024 0.50896369 0.80862266 0.45114476 0.35954806]]\n",
      "\n",
      "[[0.92142262 0.58622148 0.21628602 0.18199134 0.61834998 0.54240743]\n",
      " [0.66144277 0.09788981 0.01949405 0.78945665 0.67974322 0.26173504]\n",
      " [0.29916706 0.53482105 0.90816348 0.04192444 0.94780113 0.09030388]\n",
      " [0.83345818 0.87869257 0.55712822 0.80896268 0.3998586  0.79580228]]\n",
      "\n",
      "[[0.41723231 0.34591743 0.88468288 0.76886988 0.81339919 0.92142262\n",
      "  0.58622148 0.21628602 0.18199134 0.61834998 0.54240743]\n",
      " [0.4974245  0.06467744 0.14562472 0.32918862 0.38522401 0.66144277\n",
      "  0.09788981 0.01949405 0.78945665 0.67974322 0.26173504]\n",
      " [0.69372557 0.36821633 0.47568952 0.29220725 0.96136218 0.29916706\n",
      "  0.53482105 0.90816348 0.04192444 0.94780113 0.09030388]\n",
      " [0.34981024 0.50896369 0.80862266 0.45114476 0.35954806 0.83345818\n",
      "  0.87869257 0.55712822 0.80896268 0.3998586  0.79580228]]\n"
     ]
    }
   ],
   "source": [
    "a = np.random.rand(4, 5)\n",
    "print(a)\n",
    "print()\n",
    "\n",
    "b = np.random.rand(4, 6)\n",
    "print(b)\n",
    "print()\n",
    "\n",
    "c = np.hstack((a, b))\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Operations on Arrays\n",
    "\n",
    "Performing mathematical operations on arrays is extremely simple. Let's see some common operations.\n",
    "\n",
    "\n",
    "#### Basic Mathematical Operations\n",
    "\n",
    "NumPy provides almost all the basic math functions - exp, sin, cos, log, sqrt etc. The function is applied to each element of the array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.84147098  0.90929743  0.14112001 -0.7568025  -0.95892427 -0.2794155\n",
      "  0.6569866   0.98935825  0.41211849 -0.54402111 -0.99999021 -0.53657292\n",
      "  0.42016704  0.99060736  0.65028784 -0.28790332 -0.96139749 -0.75098725\n",
      "  0.14987721]\n",
      "[ 0.54030231 -0.41614684 -0.9899925  -0.65364362  0.28366219  0.96017029\n",
      "  0.75390225 -0.14550003 -0.91113026 -0.83907153  0.0044257   0.84385396\n",
      "  0.90744678  0.13673722 -0.75968791 -0.95765948 -0.27516334  0.66031671\n",
      "  0.98870462]\n",
      "[2.71828183e+00 7.38905610e+00 2.00855369e+01 5.45981500e+01\n",
      " 1.48413159e+02 4.03428793e+02 1.09663316e+03 2.98095799e+03\n",
      " 8.10308393e+03 2.20264658e+04 5.98741417e+04 1.62754791e+05\n",
      " 4.42413392e+05 1.20260428e+06 3.26901737e+06 8.88611052e+06\n",
      " 2.41549528e+07 6.56599691e+07 1.78482301e+08]\n",
      "[0.         0.69314718 1.09861229 1.38629436 1.60943791 1.79175947\n",
      " 1.94591015 2.07944154 2.19722458 2.30258509 2.39789527 2.48490665\n",
      " 2.56494936 2.63905733 2.7080502  2.77258872 2.83321334 2.89037176\n",
      " 2.94443898]\n"
     ]
    }
   ],
   "source": [
    "# Basic mathematical operations\n",
    "a = np.arange(1, 20)\n",
    "\n",
    "# sin, cos, exp, log\n",
    "print(np.sin(a))\n",
    "print(np.cos(a))\n",
    "print(np.exp(a))\n",
    "print(np.log(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14189215, 0.06847257, 0.2153452 , 0.69122867, 0.76355413,\n",
       "       0.60681229, 0.63591087, 0.55062461, 0.49316719, 0.45916749,\n",
       "       0.24289218, 0.5640661 , 0.56165623, 0.91685842, 0.75694209,\n",
       "       0.14005068, 0.44880079, 0.96125577, 0.03600147, 0.14170773])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_np = np.random.rand(20)\n",
    "array_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sin...\n",
      "[0.1414165  0.06841908 0.21368467 0.63748431 0.69149325 0.57025176\n",
      " 0.59391059 0.52321962 0.47341804 0.44320198 0.24051091 0.53462682\n",
      " 0.53258872 0.79369447 0.68670175 0.1395933  0.4338854  0.81991113\n",
      " 0.0359937  0.14123393]\n",
      "cos...\n",
      "[0.98995019 0.99765667 0.97690269 0.77046334 0.72238292 0.82146998\n",
      " 0.80453105 0.85219788 0.88083787 0.89642178 0.97064643 0.84508826\n",
      " 0.84637418 0.60831661 0.72693928 0.99020892 0.90096807 0.57249082\n",
      " 0.99935202 0.98997625]\n",
      "tan...\n",
      "[0.14285213 0.06857978 0.21873691 0.82740382 0.95723919 0.69418453\n",
      " 0.73820716 0.61396494 0.53746332 0.49441233 0.24778427 0.63262839\n",
      " 0.62925917 1.30473911 0.94464802 0.14097358 0.48157689 1.43218214\n",
      " 0.03601704 0.14266396]\n",
      "log...\n",
      "[-1.95268805 -2.68132205 -1.53551294 -0.36928458 -0.26977127 -0.49953577\n",
      " -0.45269686 -0.59670199 -0.70690703 -0.77834023 -1.41513763 -0.57258383\n",
      " -0.57686531 -0.08680221 -0.27846852 -1.96575092 -0.80117616 -0.03951476\n",
      " -3.3241954  -1.95398856]\n",
      "exp...\n",
      "[1.15245235 1.07087125 1.24028997 1.99616666 2.14588944 1.83457398\n",
      " 1.88874176 1.73433596 1.63749428 1.58275578 1.27493116 1.7578054\n",
      " 1.75357442 2.50141963 2.13174756 1.1503321  1.56643258 2.61497822\n",
      " 1.03665737 1.15223984]\n",
      "sqrt...\n",
      "[0.37668574 0.26167264 0.46405302 0.83140163 0.87381584 0.77898157\n",
      " 0.7974402  0.74204084 0.70225864 0.67761899 0.49284093 0.75104334\n",
      " 0.74943728 0.95752724 0.87002419 0.37423346 0.66992596 0.98043652\n",
      " 0.18974054 0.37644088]\n",
      "\n",
      "Time taken to finsh above mathmatical operation in milli seconds\n",
      "7.992982864379882e-06\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "print('sin...')\n",
    "print(np.sin(array_np))\n",
    "print('cos...')\n",
    "print(np.cos(array_np))\n",
    "print('tan...')\n",
    "print(np.tan(array_np))\n",
    "print('log...')\n",
    "print(np.log(array_np))\n",
    "print('exp...')\n",
    "print(np.exp(array_np))\n",
    "print('sqrt...')\n",
    "print(np.sqrt(array_np))\n",
    "\n",
    "\n",
    "t1 = time.time()\n",
    "print()\n",
    "print('Time taken to finsh above mathmatical operation in milli seconds')\n",
    "print((t1-t0)/1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply User Defined Functions\n",
    "\n",
    "You can also apply your own functions on arrays. For e.g. applying the function ```x/(x+1)``` to each element of an array.\n",
    "\n",
    "One way to do that is by looping through the array, which is the non-numpy way. You would rather want to write **vectorised code**. \n",
    "\n",
    "The simplest way to do that is to vectorise the function you want, and then apply it on the array. Numpy provides the ```np.vectorize()``` method to vectorise functions.\n",
    "\n",
    "Let's look at both the ways to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5, 0.6666666666666666, 0.75, 0.8, 0.8333333333333334, 0.8571428571428571, 0.875, 0.8888888888888888, 0.9, 0.9090909090909091, 0.9166666666666666, 0.9230769230769231, 0.9285714285714286, 0.9333333333333333, 0.9375, 0.9411764705882353, 0.9444444444444444, 0.9473684210526315, 0.95]\n"
     ]
    }
   ],
   "source": [
    "# The non-numpy way, not recommended\n",
    "a_list = [x/(x+1) for x in a]\n",
    "print(a_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14189215 0.06847257 0.2153452  0.69122867 0.76355413 0.60681229\n",
      " 0.63591087 0.55062461 0.49316719 0.45916749 0.24289218 0.5640661\n",
      " 0.56165623 0.91685842 0.75694209 0.14005068 0.44880079 0.96125577\n",
      " 0.03600147 0.14170773]\n"
     ]
    }
   ],
   "source": [
    "print(array_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12426054980011332, 0.06408453695306919, 0.1771885077827871, 0.4087139036698376, 0.4329632497337398, 0.3776497697700838, 0.3887197544170875, 0.3550985886101051, 0.33028263440274924, 0.3146777148079756, 0.19542498146585408, 0.36064083243039174, 0.3596542049989793, 0.4783130629209152, 0.43082927791229086, 0.12284601233661158, 0.30977398405480044, 0.4901225954660245, 0.03475040811533494, 0.12411909680249893]\n"
     ]
    }
   ],
   "source": [
    "list_of_np_array= [item/(item+1) for item in array_np]\n",
    "print(list_of_np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5       , 0.66666667, 0.75      , 0.8       , 0.83333333,\n",
       "       0.85714286, 0.875     , 0.88888889, 0.9       , 0.90909091,\n",
       "       0.91666667, 0.92307692, 0.92857143, 0.93333333, 0.9375    ,\n",
       "       0.94117647, 0.94444444, 0.94736842, 0.95      ])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The numpy way: vectorize the function, then apply it\n",
    "f = np.vectorize(lambda x: x/(x+1))\n",
    "f(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11052647, 0.06022504, 0.15051838, 0.29013265, 0.3021454 ,\n",
       "       0.27412611, 0.27991231, 0.26204631, 0.24828005, 0.23935731,\n",
       "       0.16347741, 0.26505219, 0.26451888, 0.3235533 , 0.3011046 ,\n",
       "       0.10940593, 0.2365095 , 0.32891428, 0.03358337, 0.11041454])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vactorized_fun = np.vectorize(lambda item: item/(item+1))\n",
    "vactorized_fun(list_of_np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.  12.  23.  34.  45.  56.  67.  78.  89. 100.]\n",
      "\n",
      "[0.5        0.92307692 0.95833333 0.97142857 0.97826087 0.98245614\n",
      " 0.98529412 0.98734177 0.98888889 0.99009901]\n"
     ]
    }
   ],
   "source": [
    "# Apply function on a 2-d array: Applied to each element \n",
    "b = np.linspace(1, 100, 10)\n",
    "print(b)\n",
    "print()\n",
    "print(f(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.          3.57894737  6.15789474  8.73684211 11.31578947 13.89473684\n",
      " 16.47368421 19.05263158 21.63157895 24.21052632 26.78947368 29.36842105\n",
      " 31.94736842 34.52631579 37.10526316 39.68421053 42.26315789 44.84210526\n",
      " 47.42105263 50.        ]\n",
      "\n",
      "[0.5        0.7816092  0.86029412 0.8972973  0.91880342 0.93286219\n",
      " 0.94277108 0.95013123 0.95581395 0.96033403 0.96401515 0.96707106\n",
      " 0.96964856 0.97185185 0.97375691 0.97542044 0.97688564 0.97818599\n",
      " 0.97934783 0.98039216]\n"
     ]
    }
   ],
   "source": [
    "bb = np.linspace(1, 50 ,20)\n",
    "print(bb)\n",
    "print()\n",
    "print(vactorized_fun(bb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This also has the advantage that you can vectorize the function once, and then apply it as many times as needed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply Basic Linear Algebra Operations\n",
    "\n",
    "NumPy provides the ```np.linalg``` package to apply common linear algebra operations, such as:\n",
    "* ```np.linalg.inv```: Inverse of a matrix\n",
    "* ```np.linalg.det```: Determinant of a matrix\n",
    "* ```np.linalg.eig```: Eigenvalues and eigenvectors of a matrix\n",
    "    \n",
    "Also, you can multiple matrices using ```np.dot(a, b)```. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package numpy.linalg in numpy:\n",
      "\n",
      "NAME\n",
      "    numpy.linalg\n",
      "\n",
      "DESCRIPTION\n",
      "    ``numpy.linalg``\n",
      "    ================\n",
      "    \n",
      "    The NumPy linear algebra functions rely on BLAS and LAPACK to provide efficient\n",
      "    low level implementations of standard linear algebra algorithms. Those\n",
      "    libraries may be provided by NumPy itself using C versions of a subset of their\n",
      "    reference implementations but, when possible, highly optimized libraries that\n",
      "    take advantage of specialized processor functionality are preferred. Examples\n",
      "    of such libraries are OpenBLAS, MKL (TM), and ATLAS. Because those libraries\n",
      "    are multithreaded and processor dependent, environmental variables and external\n",
      "    packages such as threadpoolctl may be needed to control the number of threads\n",
      "    or specify the processor architecture.\n",
      "    \n",
      "    - OpenBLAS: https://www.openblas.net/\n",
      "    - threadpoolctl: https://github.com/joblib/threadpoolctl\n",
      "    \n",
      "    Please note that the most-used linear algebra functions in NumPy are present in\n",
      "    the main ``numpy`` namespace rather than in ``numpy.linalg``.  There are:\n",
      "    ``dot``, ``vdot``, ``inner``, ``outer``, ``matmul``, ``tensordot``, ``einsum``,\n",
      "    ``einsum_path`` and ``kron``.\n",
      "    \n",
      "    Functions present in numpy.linalg are listed below.\n",
      "    \n",
      "    \n",
      "    Matrix and vector products\n",
      "    --------------------------\n",
      "    \n",
      "       multi_dot\n",
      "       matrix_power\n",
      "    \n",
      "    Decompositions\n",
      "    --------------\n",
      "    \n",
      "       cholesky\n",
      "       qr\n",
      "       svd\n",
      "    \n",
      "    Matrix eigenvalues\n",
      "    ------------------\n",
      "    \n",
      "       eig\n",
      "       eigh\n",
      "       eigvals\n",
      "       eigvalsh\n",
      "    \n",
      "    Norms and other numbers\n",
      "    -----------------------\n",
      "    \n",
      "       norm\n",
      "       cond\n",
      "       det\n",
      "       matrix_rank\n",
      "       slogdet\n",
      "    \n",
      "    Solving equations and inverting matrices\n",
      "    ----------------------------------------\n",
      "    \n",
      "       solve\n",
      "       tensorsolve\n",
      "       lstsq\n",
      "       inv\n",
      "       pinv\n",
      "       tensorinv\n",
      "    \n",
      "    Exceptions\n",
      "    ----------\n",
      "    \n",
      "       LinAlgError\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _umath_linalg\n",
      "    lapack_lite\n",
      "    linalg\n",
      "    setup\n",
      "    tests (package)\n",
      "\n",
      "CLASSES\n",
      "    builtins.Exception(builtins.BaseException)\n",
      "        LinAlgError\n",
      "    \n",
      "    class LinAlgError(builtins.Exception)\n",
      "     |  Generic Python-exception-derived object raised by linalg functions.\n",
      "     |  \n",
      "     |  General purpose exception class, derived from Python's exception.Exception\n",
      "     |  class, programmatically raised in linalg functions when a Linear\n",
      "     |  Algebra-related condition would prevent further correct execution of the\n",
      "     |  function.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  None\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from numpy import linalg as LA\n",
      "     |  >>> LA.inv(np.zeros((2,2)))\n",
      "     |  Traceback (most recent call last):\n",
      "     |    File \"<stdin>\", line 1, in <module>\n",
      "     |    File \"...linalg.py\", line 350,\n",
      "     |      in inv return wrap(solve(a, identity(a.shape[0], dtype=a.dtype)))\n",
      "     |    File \"...linalg.py\", line 249,\n",
      "     |      in solve\n",
      "     |      raise LinAlgError('Singular matrix')\n",
      "     |  numpy.linalg.LinAlgError: Singular matrix\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LinAlgError\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.Exception:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.Exception:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "\n",
      "FUNCTIONS\n",
      "    cholesky(a)\n",
      "        Cholesky decomposition.\n",
      "        \n",
      "        Return the Cholesky decomposition, `L * L.H`, of the square matrix `a`,\n",
      "        where `L` is lower-triangular and .H is the conjugate transpose operator\n",
      "        (which is the ordinary transpose if `a` is real-valued).  `a` must be\n",
      "        Hermitian (symmetric if real-valued) and positive-definite. No\n",
      "        checking is performed to verify whether `a` is Hermitian or not.\n",
      "        In addition, only the lower-triangular and diagonal elements of `a`\n",
      "        are used. Only `L` is actually returned.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : (..., M, M) array_like\n",
      "            Hermitian (symmetric if all elements are real), positive-definite\n",
      "            input matrix.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        L : (..., M, M) array_like\n",
      "            Upper or lower-triangular Cholesky factor of `a`.  Returns a\n",
      "            matrix object if `a` is a matrix object.\n",
      "        \n",
      "        Raises\n",
      "        ------\n",
      "        LinAlgError\n",
      "           If the decomposition fails, for example, if `a` is not\n",
      "           positive-definite.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        scipy.linalg.cholesky : Similar function in SciPy.\n",
      "        scipy.linalg.cholesky_banded : Cholesky decompose a banded Hermitian\n",
      "                                       positive-definite matrix.\n",
      "        scipy.linalg.cho_factor : Cholesky decomposition of a matrix, to use in\n",
      "                                  `scipy.linalg.cho_solve`.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        \n",
      "        .. versionadded:: 1.8.0\n",
      "        \n",
      "        Broadcasting rules apply, see the `numpy.linalg` documentation for\n",
      "        details.\n",
      "        \n",
      "        The Cholesky decomposition is often used as a fast way of solving\n",
      "        \n",
      "        .. math:: A \\mathbf{x} = \\mathbf{b}\n",
      "        \n",
      "        (when `A` is both Hermitian/symmetric and positive-definite).\n",
      "        \n",
      "        First, we solve for :math:`\\mathbf{y}` in\n",
      "        \n",
      "        .. math:: L \\mathbf{y} = \\mathbf{b},\n",
      "        \n",
      "        and then for :math:`\\mathbf{x}` in\n",
      "        \n",
      "        .. math:: L.H \\mathbf{x} = \\mathbf{y}.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> A = np.array([[1,-2j],[2j,5]])\n",
      "        >>> A\n",
      "        array([[ 1.+0.j, -0.-2.j],\n",
      "               [ 0.+2.j,  5.+0.j]])\n",
      "        >>> L = np.linalg.cholesky(A)\n",
      "        >>> L\n",
      "        array([[1.+0.j, 0.+0.j],\n",
      "               [0.+2.j, 1.+0.j]])\n",
      "        >>> np.dot(L, L.T.conj()) # verify that L * L.H = A\n",
      "        array([[1.+0.j, 0.-2.j],\n",
      "               [0.+2.j, 5.+0.j]])\n",
      "        >>> A = [[1,-2j],[2j,5]] # what happens if A is only array_like?\n",
      "        >>> np.linalg.cholesky(A) # an ndarray object is returned\n",
      "        array([[1.+0.j, 0.+0.j],\n",
      "               [0.+2.j, 1.+0.j]])\n",
      "        >>> # But a matrix object is returned if A is a matrix object\n",
      "        >>> np.linalg.cholesky(np.matrix(A))\n",
      "        matrix([[ 1.+0.j,  0.+0.j],\n",
      "                [ 0.+2.j,  1.+0.j]])\n",
      "    \n",
      "    cond(x, p=None)\n",
      "        Compute the condition number of a matrix.\n",
      "        \n",
      "        This function is capable of returning the condition number using\n",
      "        one of seven different norms, depending on the value of `p` (see\n",
      "        Parameters below).\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : (..., M, N) array_like\n",
      "            The matrix whose condition number is sought.\n",
      "        p : {None, 1, -1, 2, -2, inf, -inf, 'fro'}, optional\n",
      "            Order of the norm:\n",
      "        \n",
      "            =====  ============================\n",
      "            p      norm for matrices\n",
      "            =====  ============================\n",
      "            None   2-norm, computed directly using the ``SVD``\n",
      "            'fro'  Frobenius norm\n",
      "            inf    max(sum(abs(x), axis=1))\n",
      "            -inf   min(sum(abs(x), axis=1))\n",
      "            1      max(sum(abs(x), axis=0))\n",
      "            -1     min(sum(abs(x), axis=0))\n",
      "            2      2-norm (largest sing. value)\n",
      "            -2     smallest singular value\n",
      "            =====  ============================\n",
      "        \n",
      "            inf means the numpy.inf object, and the Frobenius norm is\n",
      "            the root-of-sum-of-squares norm.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        c : {float, inf}\n",
      "            The condition number of the matrix. May be infinite.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        numpy.linalg.norm\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The condition number of `x` is defined as the norm of `x` times the\n",
      "        norm of the inverse of `x` [1]_; the norm can be the usual L2-norm\n",
      "        (root-of-sum-of-squares) or one of a number of other matrix norms.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] G. Strang, *Linear Algebra and Its Applications*, Orlando, FL,\n",
      "               Academic Press, Inc., 1980, pg. 285.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from numpy import linalg as LA\n",
      "        >>> a = np.array([[1, 0, -1], [0, 1, 0], [1, 0, 1]])\n",
      "        >>> a\n",
      "        array([[ 1,  0, -1],\n",
      "               [ 0,  1,  0],\n",
      "               [ 1,  0,  1]])\n",
      "        >>> LA.cond(a)\n",
      "        1.4142135623730951\n",
      "        >>> LA.cond(a, 'fro')\n",
      "        3.1622776601683795\n",
      "        >>> LA.cond(a, np.inf)\n",
      "        2.0\n",
      "        >>> LA.cond(a, -np.inf)\n",
      "        1.0\n",
      "        >>> LA.cond(a, 1)\n",
      "        2.0\n",
      "        >>> LA.cond(a, -1)\n",
      "        1.0\n",
      "        >>> LA.cond(a, 2)\n",
      "        1.4142135623730951\n",
      "        >>> LA.cond(a, -2)\n",
      "        0.70710678118654746 # may vary\n",
      "        >>> min(LA.svd(a, compute_uv=False))*min(LA.svd(LA.inv(a), compute_uv=False))\n",
      "        0.70710678118654746 # may vary\n",
      "    \n",
      "    det(a)\n",
      "        Compute the determinant of an array.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : (..., M, M) array_like\n",
      "            Input array to compute determinants for.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        det : (...) array_like\n",
      "            Determinant of `a`.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        slogdet : Another way to represent the determinant, more suitable\n",
      "          for large matrices where underflow/overflow may occur.\n",
      "        scipy.linalg.det : Similar function in SciPy.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        \n",
      "        .. versionadded:: 1.8.0\n",
      "        \n",
      "        Broadcasting rules apply, see the `numpy.linalg` documentation for\n",
      "        details.\n",
      "        \n",
      "        The determinant is computed via LU factorization using the LAPACK\n",
      "        routine ``z/dgetrf``.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        The determinant of a 2-D array [[a, b], [c, d]] is ad - bc:\n",
      "        \n",
      "        >>> a = np.array([[1, 2], [3, 4]])\n",
      "        >>> np.linalg.det(a)\n",
      "        -2.0 # may vary\n",
      "        \n",
      "        Computing determinants for a stack of matrices:\n",
      "        \n",
      "        >>> a = np.array([ [[1, 2], [3, 4]], [[1, 2], [2, 1]], [[1, 3], [3, 1]] ])\n",
      "        >>> a.shape\n",
      "        (3, 2, 2)\n",
      "        >>> np.linalg.det(a)\n",
      "        array([-2., -3., -8.])\n",
      "    \n",
      "    eig(a)\n",
      "        Compute the eigenvalues and right eigenvectors of a square array.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : (..., M, M) array\n",
      "            Matrices for which the eigenvalues and right eigenvectors will\n",
      "            be computed\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        w : (..., M) array\n",
      "            The eigenvalues, each repeated according to its multiplicity.\n",
      "            The eigenvalues are not necessarily ordered. The resulting\n",
      "            array will be of complex type, unless the imaginary part is\n",
      "            zero in which case it will be cast to a real type. When `a`\n",
      "            is real the resulting eigenvalues will be real (0 imaginary\n",
      "            part) or occur in conjugate pairs\n",
      "        \n",
      "        v : (..., M, M) array\n",
      "            The normalized (unit \"length\") eigenvectors, such that the\n",
      "            column ``v[:,i]`` is the eigenvector corresponding to the\n",
      "            eigenvalue ``w[i]``.\n",
      "        \n",
      "        Raises\n",
      "        ------\n",
      "        LinAlgError\n",
      "            If the eigenvalue computation does not converge.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        eigvals : eigenvalues of a non-symmetric array.\n",
      "        eigh : eigenvalues and eigenvectors of a real symmetric or complex\n",
      "               Hermitian (conjugate symmetric) array.\n",
      "        eigvalsh : eigenvalues of a real symmetric or complex Hermitian\n",
      "                   (conjugate symmetric) array.\n",
      "        scipy.linalg.eig : Similar function in SciPy that also solves the\n",
      "                           generalized eigenvalue problem.\n",
      "        scipy.linalg.schur : Best choice for unitary and other non-Hermitian\n",
      "                             normal matrices.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        \n",
      "        .. versionadded:: 1.8.0\n",
      "        \n",
      "        Broadcasting rules apply, see the `numpy.linalg` documentation for\n",
      "        details.\n",
      "        \n",
      "        This is implemented using the ``_geev`` LAPACK routines which compute\n",
      "        the eigenvalues and eigenvectors of general square arrays.\n",
      "        \n",
      "        The number `w` is an eigenvalue of `a` if there exists a vector\n",
      "        `v` such that ``a @ v = w * v``. Thus, the arrays `a`, `w`, and\n",
      "        `v` satisfy the equations ``a @ v[:,i] = w[i] * v[:,i]``\n",
      "        for :math:`i \\in \\{0,...,M-1\\}`.\n",
      "        \n",
      "        The array `v` of eigenvectors may not be of maximum rank, that is, some\n",
      "        of the columns may be linearly dependent, although round-off error may\n",
      "        obscure that fact. If the eigenvalues are all different, then theoretically\n",
      "        the eigenvectors are linearly independent and `a` can be diagonalized by\n",
      "        a similarity transformation using `v`, i.e, ``inv(v) @ a @ v`` is diagonal.\n",
      "        \n",
      "        For non-Hermitian normal matrices the SciPy function `scipy.linalg.schur`\n",
      "        is preferred because the matrix `v` is guaranteed to be unitary, which is\n",
      "        not the case when using `eig`. The Schur factorization produces an\n",
      "        upper triangular matrix rather than a diagonal matrix, but for normal\n",
      "        matrices only the diagonal of the upper triangular matrix is needed, the\n",
      "        rest is roundoff error.\n",
      "        \n",
      "        Finally, it is emphasized that `v` consists of the *right* (as in\n",
      "        right-hand side) eigenvectors of `a`.  A vector `y` satisfying\n",
      "        ``y.T @ a = z * y.T`` for some number `z` is called a *left*\n",
      "        eigenvector of `a`, and, in general, the left and right eigenvectors\n",
      "        of a matrix are not necessarily the (perhaps conjugate) transposes\n",
      "        of each other.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        G. Strang, *Linear Algebra and Its Applications*, 2nd Ed., Orlando, FL,\n",
      "        Academic Press, Inc., 1980, Various pp.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from numpy import linalg as LA\n",
      "        \n",
      "        (Almost) trivial example with real e-values and e-vectors.\n",
      "        \n",
      "        >>> w, v = LA.eig(np.diag((1, 2, 3)))\n",
      "        >>> w; v\n",
      "        array([1., 2., 3.])\n",
      "        array([[1., 0., 0.],\n",
      "               [0., 1., 0.],\n",
      "               [0., 0., 1.]])\n",
      "        \n",
      "        Real matrix possessing complex e-values and e-vectors; note that the\n",
      "        e-values are complex conjugates of each other.\n",
      "        \n",
      "        >>> w, v = LA.eig(np.array([[1, -1], [1, 1]]))\n",
      "        >>> w; v\n",
      "        array([1.+1.j, 1.-1.j])\n",
      "        array([[0.70710678+0.j        , 0.70710678-0.j        ],\n",
      "               [0.        -0.70710678j, 0.        +0.70710678j]])\n",
      "        \n",
      "        Complex-valued matrix with real e-values (but complex-valued e-vectors);\n",
      "        note that ``a.conj().T == a``, i.e., `a` is Hermitian.\n",
      "        \n",
      "        >>> a = np.array([[1, 1j], [-1j, 1]])\n",
      "        >>> w, v = LA.eig(a)\n",
      "        >>> w; v\n",
      "        array([2.+0.j, 0.+0.j])\n",
      "        array([[ 0.        +0.70710678j,  0.70710678+0.j        ], # may vary\n",
      "               [ 0.70710678+0.j        , -0.        +0.70710678j]])\n",
      "        \n",
      "        Be careful about round-off error!\n",
      "        \n",
      "        >>> a = np.array([[1 + 1e-9, 0], [0, 1 - 1e-9]])\n",
      "        >>> # Theor. e-values are 1 +/- 1e-9\n",
      "        >>> w, v = LA.eig(a)\n",
      "        >>> w; v\n",
      "        array([1., 1.])\n",
      "        array([[1., 0.],\n",
      "               [0., 1.]])\n",
      "    \n",
      "    eigh(a, UPLO='L')\n",
      "        Return the eigenvalues and eigenvectors of a complex Hermitian\n",
      "        (conjugate symmetric) or a real symmetric matrix.\n",
      "        \n",
      "        Returns two objects, a 1-D array containing the eigenvalues of `a`, and\n",
      "        a 2-D square array or matrix (depending on the input type) of the\n",
      "        corresponding eigenvectors (in columns).\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : (..., M, M) array\n",
      "            Hermitian or real symmetric matrices whose eigenvalues and\n",
      "            eigenvectors are to be computed.\n",
      "        UPLO : {'L', 'U'}, optional\n",
      "            Specifies whether the calculation is done with the lower triangular\n",
      "            part of `a` ('L', default) or the upper triangular part ('U').\n",
      "            Irrespective of this value only the real parts of the diagonal will\n",
      "            be considered in the computation to preserve the notion of a Hermitian\n",
      "            matrix. It therefore follows that the imaginary part of the diagonal\n",
      "            will always be treated as zero.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        w : (..., M) ndarray\n",
      "            The eigenvalues in ascending order, each repeated according to\n",
      "            its multiplicity.\n",
      "        v : {(..., M, M) ndarray, (..., M, M) matrix}\n",
      "            The column ``v[:, i]`` is the normalized eigenvector corresponding\n",
      "            to the eigenvalue ``w[i]``.  Will return a matrix object if `a` is\n",
      "            a matrix object.\n",
      "        \n",
      "        Raises\n",
      "        ------\n",
      "        LinAlgError\n",
      "            If the eigenvalue computation does not converge.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        eigvalsh : eigenvalues of real symmetric or complex Hermitian\n",
      "                   (conjugate symmetric) arrays.\n",
      "        eig : eigenvalues and right eigenvectors for non-symmetric arrays.\n",
      "        eigvals : eigenvalues of non-symmetric arrays.\n",
      "        scipy.linalg.eigh : Similar function in SciPy (but also solves the\n",
      "                            generalized eigenvalue problem).\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        \n",
      "        .. versionadded:: 1.8.0\n",
      "        \n",
      "        Broadcasting rules apply, see the `numpy.linalg` documentation for\n",
      "        details.\n",
      "        \n",
      "        The eigenvalues/eigenvectors are computed using LAPACK routines ``_syevd``,\n",
      "        ``_heevd``.\n",
      "        \n",
      "        The eigenvalues of real symmetric or complex Hermitian matrices are\n",
      "        always real. [1]_ The array `v` of (column) eigenvectors is unitary\n",
      "        and `a`, `w`, and `v` satisfy the equations\n",
      "        ``dot(a, v[:, i]) = w[i] * v[:, i]``.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] G. Strang, *Linear Algebra and Its Applications*, 2nd Ed., Orlando,\n",
      "               FL, Academic Press, Inc., 1980, pg. 222.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from numpy import linalg as LA\n",
      "        >>> a = np.array([[1, -2j], [2j, 5]])\n",
      "        >>> a\n",
      "        array([[ 1.+0.j, -0.-2.j],\n",
      "               [ 0.+2.j,  5.+0.j]])\n",
      "        >>> w, v = LA.eigh(a)\n",
      "        >>> w; v\n",
      "        array([0.17157288, 5.82842712])\n",
      "        array([[-0.92387953+0.j        , -0.38268343+0.j        ], # may vary\n",
      "               [ 0.        +0.38268343j,  0.        -0.92387953j]])\n",
      "        \n",
      "        >>> np.dot(a, v[:, 0]) - w[0] * v[:, 0] # verify 1st e-val/vec pair\n",
      "        array([5.55111512e-17+0.0000000e+00j, 0.00000000e+00+1.2490009e-16j])\n",
      "        >>> np.dot(a, v[:, 1]) - w[1] * v[:, 1] # verify 2nd e-val/vec pair\n",
      "        array([0.+0.j, 0.+0.j])\n",
      "        \n",
      "        >>> A = np.matrix(a) # what happens if input is a matrix object\n",
      "        >>> A\n",
      "        matrix([[ 1.+0.j, -0.-2.j],\n",
      "                [ 0.+2.j,  5.+0.j]])\n",
      "        >>> w, v = LA.eigh(A)\n",
      "        >>> w; v\n",
      "        array([0.17157288, 5.82842712])\n",
      "        matrix([[-0.92387953+0.j        , -0.38268343+0.j        ], # may vary\n",
      "                [ 0.        +0.38268343j,  0.        -0.92387953j]])\n",
      "        \n",
      "        >>> # demonstrate the treatment of the imaginary part of the diagonal\n",
      "        >>> a = np.array([[5+2j, 9-2j], [0+2j, 2-1j]])\n",
      "        >>> a\n",
      "        array([[5.+2.j, 9.-2.j],\n",
      "               [0.+2.j, 2.-1.j]])\n",
      "        >>> # with UPLO='L' this is numerically equivalent to using LA.eig() with:\n",
      "        >>> b = np.array([[5.+0.j, 0.-2.j], [0.+2.j, 2.-0.j]])\n",
      "        >>> b\n",
      "        array([[5.+0.j, 0.-2.j],\n",
      "               [0.+2.j, 2.+0.j]])\n",
      "        >>> wa, va = LA.eigh(a)\n",
      "        >>> wb, vb = LA.eig(b)\n",
      "        >>> wa; wb\n",
      "        array([1., 6.])\n",
      "        array([6.+0.j, 1.+0.j])\n",
      "        >>> va; vb\n",
      "        array([[-0.4472136 +0.j        , -0.89442719+0.j        ], # may vary\n",
      "               [ 0.        +0.89442719j,  0.        -0.4472136j ]])\n",
      "        array([[ 0.89442719+0.j       , -0.        +0.4472136j],\n",
      "               [-0.        +0.4472136j,  0.89442719+0.j       ]])\n",
      "    \n",
      "    eigvals(a)\n",
      "        Compute the eigenvalues of a general matrix.\n",
      "        \n",
      "        Main difference between `eigvals` and `eig`: the eigenvectors aren't\n",
      "        returned.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : (..., M, M) array_like\n",
      "            A complex- or real-valued matrix whose eigenvalues will be computed.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        w : (..., M,) ndarray\n",
      "            The eigenvalues, each repeated according to its multiplicity.\n",
      "            They are not necessarily ordered, nor are they necessarily\n",
      "            real for real matrices.\n",
      "        \n",
      "        Raises\n",
      "        ------\n",
      "        LinAlgError\n",
      "            If the eigenvalue computation does not converge.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        eig : eigenvalues and right eigenvectors of general arrays\n",
      "        eigvalsh : eigenvalues of real symmetric or complex Hermitian\n",
      "                   (conjugate symmetric) arrays.\n",
      "        eigh : eigenvalues and eigenvectors of real symmetric or complex\n",
      "               Hermitian (conjugate symmetric) arrays.\n",
      "        scipy.linalg.eigvals : Similar function in SciPy.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        \n",
      "        .. versionadded:: 1.8.0\n",
      "        \n",
      "        Broadcasting rules apply, see the `numpy.linalg` documentation for\n",
      "        details.\n",
      "        \n",
      "        This is implemented using the ``_geev`` LAPACK routines which compute\n",
      "        the eigenvalues and eigenvectors of general square arrays.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Illustration, using the fact that the eigenvalues of a diagonal matrix\n",
      "        are its diagonal elements, that multiplying a matrix on the left\n",
      "        by an orthogonal matrix, `Q`, and on the right by `Q.T` (the transpose\n",
      "        of `Q`), preserves the eigenvalues of the \"middle\" matrix.  In other words,\n",
      "        if `Q` is orthogonal, then ``Q * A * Q.T`` has the same eigenvalues as\n",
      "        ``A``:\n",
      "        \n",
      "        >>> from numpy import linalg as LA\n",
      "        >>> x = np.random.random()\n",
      "        >>> Q = np.array([[np.cos(x), -np.sin(x)], [np.sin(x), np.cos(x)]])\n",
      "        >>> LA.norm(Q[0, :]), LA.norm(Q[1, :]), np.dot(Q[0, :],Q[1, :])\n",
      "        (1.0, 1.0, 0.0)\n",
      "        \n",
      "        Now multiply a diagonal matrix by ``Q`` on one side and by ``Q.T`` on the other:\n",
      "        \n",
      "        >>> D = np.diag((-1,1))\n",
      "        >>> LA.eigvals(D)\n",
      "        array([-1.,  1.])\n",
      "        >>> A = np.dot(Q, D)\n",
      "        >>> A = np.dot(A, Q.T)\n",
      "        >>> LA.eigvals(A)\n",
      "        array([ 1., -1.]) # random\n",
      "    \n",
      "    eigvalsh(a, UPLO='L')\n",
      "        Compute the eigenvalues of a complex Hermitian or real symmetric matrix.\n",
      "        \n",
      "        Main difference from eigh: the eigenvectors are not computed.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : (..., M, M) array_like\n",
      "            A complex- or real-valued matrix whose eigenvalues are to be\n",
      "            computed.\n",
      "        UPLO : {'L', 'U'}, optional\n",
      "            Specifies whether the calculation is done with the lower triangular\n",
      "            part of `a` ('L', default) or the upper triangular part ('U').\n",
      "            Irrespective of this value only the real parts of the diagonal will\n",
      "            be considered in the computation to preserve the notion of a Hermitian\n",
      "            matrix. It therefore follows that the imaginary part of the diagonal\n",
      "            will always be treated as zero.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        w : (..., M,) ndarray\n",
      "            The eigenvalues in ascending order, each repeated according to\n",
      "            its multiplicity.\n",
      "        \n",
      "        Raises\n",
      "        ------\n",
      "        LinAlgError\n",
      "            If the eigenvalue computation does not converge.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        eigh : eigenvalues and eigenvectors of real symmetric or complex Hermitian\n",
      "               (conjugate symmetric) arrays.\n",
      "        eigvals : eigenvalues of general real or complex arrays.\n",
      "        eig : eigenvalues and right eigenvectors of general real or complex\n",
      "              arrays.\n",
      "        scipy.linalg.eigvalsh : Similar function in SciPy.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        \n",
      "        .. versionadded:: 1.8.0\n",
      "        \n",
      "        Broadcasting rules apply, see the `numpy.linalg` documentation for\n",
      "        details.\n",
      "        \n",
      "        The eigenvalues are computed using LAPACK routines ``_syevd``, ``_heevd``.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from numpy import linalg as LA\n",
      "        >>> a = np.array([[1, -2j], [2j, 5]])\n",
      "        >>> LA.eigvalsh(a)\n",
      "        array([ 0.17157288,  5.82842712]) # may vary\n",
      "        \n",
      "        >>> # demonstrate the treatment of the imaginary part of the diagonal\n",
      "        >>> a = np.array([[5+2j, 9-2j], [0+2j, 2-1j]])\n",
      "        >>> a\n",
      "        array([[5.+2.j, 9.-2.j],\n",
      "               [0.+2.j, 2.-1.j]])\n",
      "        >>> # with UPLO='L' this is numerically equivalent to using LA.eigvals()\n",
      "        >>> # with:\n",
      "        >>> b = np.array([[5.+0.j, 0.-2.j], [0.+2.j, 2.-0.j]])\n",
      "        >>> b\n",
      "        array([[5.+0.j, 0.-2.j],\n",
      "               [0.+2.j, 2.+0.j]])\n",
      "        >>> wa = LA.eigvalsh(a)\n",
      "        >>> wb = LA.eigvals(b)\n",
      "        >>> wa; wb\n",
      "        array([1., 6.])\n",
      "        array([6.+0.j, 1.+0.j])\n",
      "    \n",
      "    inv(a)\n",
      "        Compute the (multiplicative) inverse of a matrix.\n",
      "        \n",
      "        Given a square matrix `a`, return the matrix `ainv` satisfying\n",
      "        ``dot(a, ainv) = dot(ainv, a) = eye(a.shape[0])``.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : (..., M, M) array_like\n",
      "            Matrix to be inverted.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        ainv : (..., M, M) ndarray or matrix\n",
      "            (Multiplicative) inverse of the matrix `a`.\n",
      "        \n",
      "        Raises\n",
      "        ------\n",
      "        LinAlgError\n",
      "            If `a` is not square or inversion fails.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        scipy.linalg.inv : Similar function in SciPy.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        \n",
      "        .. versionadded:: 1.8.0\n",
      "        \n",
      "        Broadcasting rules apply, see the `numpy.linalg` documentation for\n",
      "        details.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from numpy.linalg import inv\n",
      "        >>> a = np.array([[1., 2.], [3., 4.]])\n",
      "        >>> ainv = inv(a)\n",
      "        >>> np.allclose(np.dot(a, ainv), np.eye(2))\n",
      "        True\n",
      "        >>> np.allclose(np.dot(ainv, a), np.eye(2))\n",
      "        True\n",
      "        \n",
      "        If a is a matrix object, then the return value is a matrix as well:\n",
      "        \n",
      "        >>> ainv = inv(np.matrix(a))\n",
      "        >>> ainv\n",
      "        matrix([[-2. ,  1. ],\n",
      "                [ 1.5, -0.5]])\n",
      "        \n",
      "        Inverses of several matrices can be computed at once:\n",
      "        \n",
      "        >>> a = np.array([[[1., 2.], [3., 4.]], [[1, 3], [3, 5]]])\n",
      "        >>> inv(a)\n",
      "        array([[[-2.  ,  1.  ],\n",
      "                [ 1.5 , -0.5 ]],\n",
      "               [[-1.25,  0.75],\n",
      "                [ 0.75, -0.25]]])\n",
      "    \n",
      "    lstsq(a, b, rcond='warn')\n",
      "        Return the least-squares solution to a linear matrix equation.\n",
      "        \n",
      "        Computes the vector `x` that approximatively solves the equation\n",
      "        ``a @ x = b``. The equation may be under-, well-, or over-determined\n",
      "        (i.e., the number of linearly independent rows of `a` can be less than,\n",
      "        equal to, or greater than its number of linearly independent columns).\n",
      "        If `a` is square and of full rank, then `x` (but for round-off error)\n",
      "        is the \"exact\" solution of the equation. Else, `x` minimizes the\n",
      "        Euclidean 2-norm :math:`||b - ax||`. If there are multiple minimizing \n",
      "        solutions, the one with the smallest 2-norm :math:`||x||` is returned.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : (M, N) array_like\n",
      "            \"Coefficient\" matrix.\n",
      "        b : {(M,), (M, K)} array_like\n",
      "            Ordinate or \"dependent variable\" values. If `b` is two-dimensional,\n",
      "            the least-squares solution is calculated for each of the `K` columns\n",
      "            of `b`.\n",
      "        rcond : float, optional\n",
      "            Cut-off ratio for small singular values of `a`.\n",
      "            For the purposes of rank determination, singular values are treated\n",
      "            as zero if they are smaller than `rcond` times the largest singular\n",
      "            value of `a`.\n",
      "        \n",
      "            .. versionchanged:: 1.14.0\n",
      "               If not set, a FutureWarning is given. The previous default\n",
      "               of ``-1`` will use the machine precision as `rcond` parameter,\n",
      "               the new default will use the machine precision times `max(M, N)`.\n",
      "               To silence the warning and use the new default, use ``rcond=None``,\n",
      "               to keep using the old behavior, use ``rcond=-1``.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        x : {(N,), (N, K)} ndarray\n",
      "            Least-squares solution. If `b` is two-dimensional,\n",
      "            the solutions are in the `K` columns of `x`.\n",
      "        residuals : {(1,), (K,), (0,)} ndarray\n",
      "            Sums of squared residuals: Squared Euclidean 2-norm for each column in\n",
      "            ``b - a @ x``.\n",
      "            If the rank of `a` is < N or M <= N, this is an empty array.\n",
      "            If `b` is 1-dimensional, this is a (1,) shape array.\n",
      "            Otherwise the shape is (K,).\n",
      "        rank : int\n",
      "            Rank of matrix `a`.\n",
      "        s : (min(M, N),) ndarray\n",
      "            Singular values of `a`.\n",
      "        \n",
      "        Raises\n",
      "        ------\n",
      "        LinAlgError\n",
      "            If computation does not converge.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        scipy.linalg.lstsq : Similar function in SciPy.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        If `b` is a matrix, then all array results are returned as matrices.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Fit a line, ``y = mx + c``, through some noisy data-points:\n",
      "        \n",
      "        >>> x = np.array([0, 1, 2, 3])\n",
      "        >>> y = np.array([-1, 0.2, 0.9, 2.1])\n",
      "        \n",
      "        By examining the coefficients, we see that the line should have a\n",
      "        gradient of roughly 1 and cut the y-axis at, more or less, -1.\n",
      "        \n",
      "        We can rewrite the line equation as ``y = Ap``, where ``A = [[x 1]]``\n",
      "        and ``p = [[m], [c]]``.  Now use `lstsq` to solve for `p`:\n",
      "        \n",
      "        >>> A = np.vstack([x, np.ones(len(x))]).T\n",
      "        >>> A\n",
      "        array([[ 0.,  1.],\n",
      "               [ 1.,  1.],\n",
      "               [ 2.,  1.],\n",
      "               [ 3.,  1.]])\n",
      "        \n",
      "        >>> m, c = np.linalg.lstsq(A, y, rcond=None)[0]\n",
      "        >>> m, c\n",
      "        (1.0 -0.95) # may vary\n",
      "        \n",
      "        Plot the data along with the fitted line:\n",
      "        \n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        >>> _ = plt.plot(x, y, 'o', label='Original data', markersize=10)\n",
      "        >>> _ = plt.plot(x, m*x + c, 'r', label='Fitted line')\n",
      "        >>> _ = plt.legend()\n",
      "        >>> plt.show()\n",
      "    \n",
      "    matrix_power(a, n)\n",
      "        Raise a square matrix to the (integer) power `n`.\n",
      "        \n",
      "        For positive integers `n`, the power is computed by repeated matrix\n",
      "        squarings and matrix multiplications. If ``n == 0``, the identity matrix\n",
      "        of the same shape as M is returned. If ``n < 0``, the inverse\n",
      "        is computed and then raised to the ``abs(n)``.\n",
      "        \n",
      "        .. note:: Stacks of object matrices are not currently supported.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : (..., M, M) array_like\n",
      "            Matrix to be \"powered\".\n",
      "        n : int\n",
      "            The exponent can be any integer or long integer, positive,\n",
      "            negative, or zero.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        a**n : (..., M, M) ndarray or matrix object\n",
      "            The return value is the same shape and type as `M`;\n",
      "            if the exponent is positive or zero then the type of the\n",
      "            elements is the same as those of `M`. If the exponent is\n",
      "            negative the elements are floating-point.\n",
      "        \n",
      "        Raises\n",
      "        ------\n",
      "        LinAlgError\n",
      "            For matrices that are not square or that (for negative powers) cannot\n",
      "            be inverted numerically.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from numpy.linalg import matrix_power\n",
      "        >>> i = np.array([[0, 1], [-1, 0]]) # matrix equiv. of the imaginary unit\n",
      "        >>> matrix_power(i, 3) # should = -i\n",
      "        array([[ 0, -1],\n",
      "               [ 1,  0]])\n",
      "        >>> matrix_power(i, 0)\n",
      "        array([[1, 0],\n",
      "               [0, 1]])\n",
      "        >>> matrix_power(i, -3) # should = 1/(-i) = i, but w/ f.p. elements\n",
      "        array([[ 0.,  1.],\n",
      "               [-1.,  0.]])\n",
      "        \n",
      "        Somewhat more sophisticated example\n",
      "        \n",
      "        >>> q = np.zeros((4, 4))\n",
      "        >>> q[0:2, 0:2] = -i\n",
      "        >>> q[2:4, 2:4] = i\n",
      "        >>> q # one of the three quaternion units not equal to 1\n",
      "        array([[ 0., -1.,  0.,  0.],\n",
      "               [ 1.,  0.,  0.,  0.],\n",
      "               [ 0.,  0.,  0.,  1.],\n",
      "               [ 0.,  0., -1.,  0.]])\n",
      "        >>> matrix_power(q, 2) # = -np.eye(4)\n",
      "        array([[-1.,  0.,  0.,  0.],\n",
      "               [ 0., -1.,  0.,  0.],\n",
      "               [ 0.,  0., -1.,  0.],\n",
      "               [ 0.,  0.,  0., -1.]])\n",
      "    \n",
      "    matrix_rank(M, tol=None, hermitian=False)\n",
      "        Return matrix rank of array using SVD method\n",
      "        \n",
      "        Rank of the array is the number of singular values of the array that are\n",
      "        greater than `tol`.\n",
      "        \n",
      "        .. versionchanged:: 1.14\n",
      "           Can now operate on stacks of matrices\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        M : {(M,), (..., M, N)} array_like\n",
      "            Input vector or stack of matrices.\n",
      "        tol : (...) array_like, float, optional\n",
      "            Threshold below which SVD values are considered zero. If `tol` is\n",
      "            None, and ``S`` is an array with singular values for `M`, and\n",
      "            ``eps`` is the epsilon value for datatype of ``S``, then `tol` is\n",
      "            set to ``S.max() * max(M.shape) * eps``.\n",
      "        \n",
      "            .. versionchanged:: 1.14\n",
      "               Broadcasted against the stack of matrices\n",
      "        hermitian : bool, optional\n",
      "            If True, `M` is assumed to be Hermitian (symmetric if real-valued),\n",
      "            enabling a more efficient method for finding singular values.\n",
      "            Defaults to False.\n",
      "        \n",
      "            .. versionadded:: 1.14\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        rank : (...) array_like\n",
      "            Rank of M.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The default threshold to detect rank deficiency is a test on the magnitude\n",
      "        of the singular values of `M`.  By default, we identify singular values less\n",
      "        than ``S.max() * max(M.shape) * eps`` as indicating rank deficiency (with\n",
      "        the symbols defined above). This is the algorithm MATLAB uses [1].  It also\n",
      "        appears in *Numerical recipes* in the discussion of SVD solutions for linear\n",
      "        least squares [2].\n",
      "        \n",
      "        This default threshold is designed to detect rank deficiency accounting for\n",
      "        the numerical errors of the SVD computation.  Imagine that there is a column\n",
      "        in `M` that is an exact (in floating point) linear combination of other\n",
      "        columns in `M`. Computing the SVD on `M` will not produce a singular value\n",
      "        exactly equal to 0 in general: any difference of the smallest SVD value from\n",
      "        0 will be caused by numerical imprecision in the calculation of the SVD.\n",
      "        Our threshold for small SVD values takes this numerical imprecision into\n",
      "        account, and the default threshold will detect such numerical rank\n",
      "        deficiency.  The threshold may declare a matrix `M` rank deficient even if\n",
      "        the linear combination of some columns of `M` is not exactly equal to\n",
      "        another column of `M` but only numerically very close to another column of\n",
      "        `M`.\n",
      "        \n",
      "        We chose our default threshold because it is in wide use.  Other thresholds\n",
      "        are possible.  For example, elsewhere in the 2007 edition of *Numerical\n",
      "        recipes* there is an alternative threshold of ``S.max() *\n",
      "        np.finfo(M.dtype).eps / 2. * np.sqrt(m + n + 1.)``. The authors describe\n",
      "        this threshold as being based on \"expected roundoff error\" (p 71).\n",
      "        \n",
      "        The thresholds above deal with floating point roundoff error in the\n",
      "        calculation of the SVD.  However, you may have more information about the\n",
      "        sources of error in `M` that would make you consider other tolerance values\n",
      "        to detect *effective* rank deficiency.  The most useful measure of the\n",
      "        tolerance depends on the operations you intend to use on your matrix.  For\n",
      "        example, if your data come from uncertain measurements with uncertainties\n",
      "        greater than floating point epsilon, choosing a tolerance near that\n",
      "        uncertainty may be preferable.  The tolerance may be absolute if the\n",
      "        uncertainties are absolute rather than relative.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] MATLAB reference documention, \"Rank\"\n",
      "               https://www.mathworks.com/help/techdoc/ref/rank.html\n",
      "        .. [2] W. H. Press, S. A. Teukolsky, W. T. Vetterling and B. P. Flannery,\n",
      "               \"Numerical Recipes (3rd edition)\", Cambridge University Press, 2007,\n",
      "               page 795.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from numpy.linalg import matrix_rank\n",
      "        >>> matrix_rank(np.eye(4)) # Full rank matrix\n",
      "        4\n",
      "        >>> I=np.eye(4); I[-1,-1] = 0. # rank deficient matrix\n",
      "        >>> matrix_rank(I)\n",
      "        3\n",
      "        >>> matrix_rank(np.ones((4,))) # 1 dimension - rank 1 unless all 0\n",
      "        1\n",
      "        >>> matrix_rank(np.zeros((4,)))\n",
      "        0\n",
      "    \n",
      "    multi_dot(arrays, *, out=None)\n",
      "        Compute the dot product of two or more arrays in a single function call,\n",
      "        while automatically selecting the fastest evaluation order.\n",
      "        \n",
      "        `multi_dot` chains `numpy.dot` and uses optimal parenthesization\n",
      "        of the matrices [1]_ [2]_. Depending on the shapes of the matrices,\n",
      "        this can speed up the multiplication a lot.\n",
      "        \n",
      "        If the first argument is 1-D it is treated as a row vector.\n",
      "        If the last argument is 1-D it is treated as a column vector.\n",
      "        The other arguments must be 2-D.\n",
      "        \n",
      "        Think of `multi_dot` as::\n",
      "        \n",
      "            def multi_dot(arrays): return functools.reduce(np.dot, arrays)\n",
      "        \n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        arrays : sequence of array_like\n",
      "            If the first argument is 1-D it is treated as row vector.\n",
      "            If the last argument is 1-D it is treated as column vector.\n",
      "            The other arguments must be 2-D.\n",
      "        out : ndarray, optional\n",
      "            Output argument. This must have the exact kind that would be returned\n",
      "            if it was not used. In particular, it must have the right type, must be\n",
      "            C-contiguous, and its dtype must be the dtype that would be returned\n",
      "            for `dot(a, b)`. This is a performance feature. Therefore, if these\n",
      "            conditions are not met, an exception is raised, instead of attempting\n",
      "            to be flexible.\n",
      "        \n",
      "            .. versionadded:: 1.19.0\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        output : ndarray\n",
      "            Returns the dot product of the supplied arrays.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        numpy.dot : dot multiplication with two arguments.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        \n",
      "        .. [1] Cormen, \"Introduction to Algorithms\", Chapter 15.2, p. 370-378\n",
      "        .. [2] https://en.wikipedia.org/wiki/Matrix_chain_multiplication\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        `multi_dot` allows you to write::\n",
      "        \n",
      "        >>> from numpy.linalg import multi_dot\n",
      "        >>> # Prepare some data\n",
      "        >>> A = np.random.random((10000, 100))\n",
      "        >>> B = np.random.random((100, 1000))\n",
      "        >>> C = np.random.random((1000, 5))\n",
      "        >>> D = np.random.random((5, 333))\n",
      "        >>> # the actual dot multiplication\n",
      "        >>> _ = multi_dot([A, B, C, D])\n",
      "        \n",
      "        instead of::\n",
      "        \n",
      "        >>> _ = np.dot(np.dot(np.dot(A, B), C), D)\n",
      "        >>> # or\n",
      "        >>> _ = A.dot(B).dot(C).dot(D)\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The cost for a matrix multiplication can be calculated with the\n",
      "        following function::\n",
      "        \n",
      "            def cost(A, B):\n",
      "                return A.shape[0] * A.shape[1] * B.shape[1]\n",
      "        \n",
      "        Assume we have three matrices\n",
      "        :math:`A_{10x100}, B_{100x5}, C_{5x50}`.\n",
      "        \n",
      "        The costs for the two different parenthesizations are as follows::\n",
      "        \n",
      "            cost((AB)C) = 10*100*5 + 10*5*50   = 5000 + 2500   = 7500\n",
      "            cost(A(BC)) = 10*100*50 + 100*5*50 = 50000 + 25000 = 75000\n",
      "    \n",
      "    norm(x, ord=None, axis=None, keepdims=False)\n",
      "        Matrix or vector norm.\n",
      "        \n",
      "        This function is able to return one of eight different matrix norms,\n",
      "        or one of an infinite number of vector norms (described below), depending\n",
      "        on the value of the ``ord`` parameter.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like\n",
      "            Input array.  If `axis` is None, `x` must be 1-D or 2-D, unless `ord`\n",
      "            is None. If both `axis` and `ord` are None, the 2-norm of\n",
      "            ``x.ravel`` will be returned.\n",
      "        ord : {non-zero int, inf, -inf, 'fro', 'nuc'}, optional\n",
      "            Order of the norm (see table under ``Notes``). inf means numpy's\n",
      "            `inf` object. The default is None.\n",
      "        axis : {None, int, 2-tuple of ints}, optional.\n",
      "            If `axis` is an integer, it specifies the axis of `x` along which to\n",
      "            compute the vector norms.  If `axis` is a 2-tuple, it specifies the\n",
      "            axes that hold 2-D matrices, and the matrix norms of these matrices\n",
      "            are computed.  If `axis` is None then either a vector norm (when `x`\n",
      "            is 1-D) or a matrix norm (when `x` is 2-D) is returned. The default\n",
      "            is None.\n",
      "        \n",
      "            .. versionadded:: 1.8.0\n",
      "        \n",
      "        keepdims : bool, optional\n",
      "            If this is set to True, the axes which are normed over are left in the\n",
      "            result as dimensions with size one.  With this option the result will\n",
      "            broadcast correctly against the original `x`.\n",
      "        \n",
      "            .. versionadded:: 1.10.0\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        n : float or ndarray\n",
      "            Norm of the matrix or vector(s).\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        scipy.linalg.norm : Similar function in SciPy.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        For values of ``ord < 1``, the result is, strictly speaking, not a\n",
      "        mathematical 'norm', but it may still be useful for various numerical\n",
      "        purposes.\n",
      "        \n",
      "        The following norms can be calculated:\n",
      "        \n",
      "        =====  ============================  ==========================\n",
      "        ord    norm for matrices             norm for vectors\n",
      "        =====  ============================  ==========================\n",
      "        None   Frobenius norm                2-norm\n",
      "        'fro'  Frobenius norm                --\n",
      "        'nuc'  nuclear norm                  --\n",
      "        inf    max(sum(abs(x), axis=1))      max(abs(x))\n",
      "        -inf   min(sum(abs(x), axis=1))      min(abs(x))\n",
      "        0      --                            sum(x != 0)\n",
      "        1      max(sum(abs(x), axis=0))      as below\n",
      "        -1     min(sum(abs(x), axis=0))      as below\n",
      "        2      2-norm (largest sing. value)  as below\n",
      "        -2     smallest singular value       as below\n",
      "        other  --                            sum(abs(x)**ord)**(1./ord)\n",
      "        =====  ============================  ==========================\n",
      "        \n",
      "        The Frobenius norm is given by [1]_:\n",
      "        \n",
      "            :math:`||A||_F = [\\sum_{i,j} abs(a_{i,j})^2]^{1/2}`\n",
      "        \n",
      "        The nuclear norm is the sum of the singular values.\n",
      "        \n",
      "        Both the Frobenius and nuclear norm orders are only defined for\n",
      "        matrices and raise a ValueError when ``x.ndim != 2``.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] G. H. Golub and C. F. Van Loan, *Matrix Computations*,\n",
      "               Baltimore, MD, Johns Hopkins University Press, 1985, pg. 15\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from numpy import linalg as LA\n",
      "        >>> a = np.arange(9) - 4\n",
      "        >>> a\n",
      "        array([-4, -3, -2, ...,  2,  3,  4])\n",
      "        >>> b = a.reshape((3, 3))\n",
      "        >>> b\n",
      "        array([[-4, -3, -2],\n",
      "               [-1,  0,  1],\n",
      "               [ 2,  3,  4]])\n",
      "        \n",
      "        >>> LA.norm(a)\n",
      "        7.745966692414834\n",
      "        >>> LA.norm(b)\n",
      "        7.745966692414834\n",
      "        >>> LA.norm(b, 'fro')\n",
      "        7.745966692414834\n",
      "        >>> LA.norm(a, np.inf)\n",
      "        4.0\n",
      "        >>> LA.norm(b, np.inf)\n",
      "        9.0\n",
      "        >>> LA.norm(a, -np.inf)\n",
      "        0.0\n",
      "        >>> LA.norm(b, -np.inf)\n",
      "        2.0\n",
      "        \n",
      "        >>> LA.norm(a, 1)\n",
      "        20.0\n",
      "        >>> LA.norm(b, 1)\n",
      "        7.0\n",
      "        >>> LA.norm(a, -1)\n",
      "        -4.6566128774142013e-010\n",
      "        >>> LA.norm(b, -1)\n",
      "        6.0\n",
      "        >>> LA.norm(a, 2)\n",
      "        7.745966692414834\n",
      "        >>> LA.norm(b, 2)\n",
      "        7.3484692283495345\n",
      "        \n",
      "        >>> LA.norm(a, -2)\n",
      "        0.0\n",
      "        >>> LA.norm(b, -2)\n",
      "        1.8570331885190563e-016 # may vary\n",
      "        >>> LA.norm(a, 3)\n",
      "        5.8480354764257312 # may vary\n",
      "        >>> LA.norm(a, -3)\n",
      "        0.0\n",
      "        \n",
      "        Using the `axis` argument to compute vector norms:\n",
      "        \n",
      "        >>> c = np.array([[ 1, 2, 3],\n",
      "        ...               [-1, 1, 4]])\n",
      "        >>> LA.norm(c, axis=0)\n",
      "        array([ 1.41421356,  2.23606798,  5.        ])\n",
      "        >>> LA.norm(c, axis=1)\n",
      "        array([ 3.74165739,  4.24264069])\n",
      "        >>> LA.norm(c, ord=1, axis=1)\n",
      "        array([ 6.,  6.])\n",
      "        \n",
      "        Using the `axis` argument to compute matrix norms:\n",
      "        \n",
      "        >>> m = np.arange(8).reshape(2,2,2)\n",
      "        >>> LA.norm(m, axis=(1,2))\n",
      "        array([  3.74165739,  11.22497216])\n",
      "        >>> LA.norm(m[0, :, :]), LA.norm(m[1, :, :])\n",
      "        (3.7416573867739413, 11.224972160321824)\n",
      "    \n",
      "    pinv(a, rcond=1e-15, hermitian=False)\n",
      "        Compute the (Moore-Penrose) pseudo-inverse of a matrix.\n",
      "        \n",
      "        Calculate the generalized inverse of a matrix using its\n",
      "        singular-value decomposition (SVD) and including all\n",
      "        *large* singular values.\n",
      "        \n",
      "        .. versionchanged:: 1.14\n",
      "           Can now operate on stacks of matrices\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : (..., M, N) array_like\n",
      "            Matrix or stack of matrices to be pseudo-inverted.\n",
      "        rcond : (...) array_like of float\n",
      "            Cutoff for small singular values.\n",
      "            Singular values less than or equal to\n",
      "            ``rcond * largest_singular_value`` are set to zero.\n",
      "            Broadcasts against the stack of matrices.\n",
      "        hermitian : bool, optional\n",
      "            If True, `a` is assumed to be Hermitian (symmetric if real-valued),\n",
      "            enabling a more efficient method for finding singular values.\n",
      "            Defaults to False.\n",
      "        \n",
      "            .. versionadded:: 1.17.0\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        B : (..., N, M) ndarray\n",
      "            The pseudo-inverse of `a`. If `a` is a `matrix` instance, then so\n",
      "            is `B`.\n",
      "        \n",
      "        Raises\n",
      "        ------\n",
      "        LinAlgError\n",
      "            If the SVD computation does not converge.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        scipy.linalg.pinv : Similar function in SciPy.\n",
      "        scipy.linalg.pinv2 : Similar function in SciPy (SVD-based).\n",
      "        scipy.linalg.pinvh : Compute the (Moore-Penrose) pseudo-inverse of a\n",
      "                             Hermitian matrix.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The pseudo-inverse of a matrix A, denoted :math:`A^+`, is\n",
      "        defined as: \"the matrix that 'solves' [the least-squares problem]\n",
      "        :math:`Ax = b`,\" i.e., if :math:`\\bar{x}` is said solution, then\n",
      "        :math:`A^+` is that matrix such that :math:`\\bar{x} = A^+b`.\n",
      "        \n",
      "        It can be shown that if :math:`Q_1 \\Sigma Q_2^T = A` is the singular\n",
      "        value decomposition of A, then\n",
      "        :math:`A^+ = Q_2 \\Sigma^+ Q_1^T`, where :math:`Q_{1,2}` are\n",
      "        orthogonal matrices, :math:`\\Sigma` is a diagonal matrix consisting\n",
      "        of A's so-called singular values, (followed, typically, by\n",
      "        zeros), and then :math:`\\Sigma^+` is simply the diagonal matrix\n",
      "        consisting of the reciprocals of A's singular values\n",
      "        (again, followed by zeros). [1]_\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] G. Strang, *Linear Algebra and Its Applications*, 2nd Ed., Orlando,\n",
      "               FL, Academic Press, Inc., 1980, pp. 139-142.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        The following example checks that ``a * a+ * a == a`` and\n",
      "        ``a+ * a * a+ == a+``:\n",
      "        \n",
      "        >>> a = np.random.randn(9, 6)\n",
      "        >>> B = np.linalg.pinv(a)\n",
      "        >>> np.allclose(a, np.dot(a, np.dot(B, a)))\n",
      "        True\n",
      "        >>> np.allclose(B, np.dot(B, np.dot(a, B)))\n",
      "        True\n",
      "    \n",
      "    qr(a, mode='reduced')\n",
      "        Compute the qr factorization of a matrix.\n",
      "        \n",
      "        Factor the matrix `a` as *qr*, where `q` is orthonormal and `r` is\n",
      "        upper-triangular.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like, shape (M, N)\n",
      "            Matrix to be factored.\n",
      "        mode : {'reduced', 'complete', 'r', 'raw'}, optional\n",
      "            If K = min(M, N), then\n",
      "        \n",
      "            * 'reduced'  : returns q, r with dimensions (M, K), (K, N) (default)\n",
      "            * 'complete' : returns q, r with dimensions (M, M), (M, N)\n",
      "            * 'r'        : returns r only with dimensions (K, N)\n",
      "            * 'raw'      : returns h, tau with dimensions (N, M), (K,)\n",
      "        \n",
      "            The options 'reduced', 'complete, and 'raw' are new in numpy 1.8,\n",
      "            see the notes for more information. The default is 'reduced', and to\n",
      "            maintain backward compatibility with earlier versions of numpy both\n",
      "            it and the old default 'full' can be omitted. Note that array h\n",
      "            returned in 'raw' mode is transposed for calling Fortran. The\n",
      "            'economic' mode is deprecated.  The modes 'full' and 'economic' may\n",
      "            be passed using only the first letter for backwards compatibility,\n",
      "            but all others must be spelled out. See the Notes for more\n",
      "            explanation.\n",
      "        \n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        q : ndarray of float or complex, optional\n",
      "            A matrix with orthonormal columns. When mode = 'complete' the\n",
      "            result is an orthogonal/unitary matrix depending on whether or not\n",
      "            a is real/complex. The determinant may be either +/- 1 in that\n",
      "            case.\n",
      "        r : ndarray of float or complex, optional\n",
      "            The upper-triangular matrix.\n",
      "        (h, tau) : ndarrays of np.double or np.cdouble, optional\n",
      "            The array h contains the Householder reflectors that generate q\n",
      "            along with r. The tau array contains scaling factors for the\n",
      "            reflectors. In the deprecated  'economic' mode only h is returned.\n",
      "        \n",
      "        Raises\n",
      "        ------\n",
      "        LinAlgError\n",
      "            If factoring fails.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        scipy.linalg.qr : Similar function in SciPy.\n",
      "        scipy.linalg.rq : Compute RQ decomposition of a matrix.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This is an interface to the LAPACK routines ``dgeqrf``, ``zgeqrf``,\n",
      "        ``dorgqr``, and ``zungqr``.\n",
      "        \n",
      "        For more information on the qr factorization, see for example:\n",
      "        https://en.wikipedia.org/wiki/QR_factorization\n",
      "        \n",
      "        Subclasses of `ndarray` are preserved except for the 'raw' mode. So if\n",
      "        `a` is of type `matrix`, all the return values will be matrices too.\n",
      "        \n",
      "        New 'reduced', 'complete', and 'raw' options for mode were added in\n",
      "        NumPy 1.8.0 and the old option 'full' was made an alias of 'reduced'.  In\n",
      "        addition the options 'full' and 'economic' were deprecated.  Because\n",
      "        'full' was the previous default and 'reduced' is the new default,\n",
      "        backward compatibility can be maintained by letting `mode` default.\n",
      "        The 'raw' option was added so that LAPACK routines that can multiply\n",
      "        arrays by q using the Householder reflectors can be used. Note that in\n",
      "        this case the returned arrays are of type np.double or np.cdouble and\n",
      "        the h array is transposed to be FORTRAN compatible.  No routines using\n",
      "        the 'raw' return are currently exposed by numpy, but some are available\n",
      "        in lapack_lite and just await the necessary work.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> a = np.random.randn(9, 6)\n",
      "        >>> q, r = np.linalg.qr(a)\n",
      "        >>> np.allclose(a, np.dot(q, r))  # a does equal qr\n",
      "        True\n",
      "        >>> r2 = np.linalg.qr(a, mode='r')\n",
      "        >>> np.allclose(r, r2)  # mode='r' returns the same r as mode='full'\n",
      "        True\n",
      "        \n",
      "        Example illustrating a common use of `qr`: solving of least squares\n",
      "        problems\n",
      "        \n",
      "        What are the least-squares-best `m` and `y0` in ``y = y0 + mx`` for\n",
      "        the following data: {(0,1), (1,0), (1,2), (2,1)}. (Graph the points\n",
      "        and you'll see that it should be y0 = 0, m = 1.)  The answer is provided\n",
      "        by solving the over-determined matrix equation ``Ax = b``, where::\n",
      "        \n",
      "          A = array([[0, 1], [1, 1], [1, 1], [2, 1]])\n",
      "          x = array([[y0], [m]])\n",
      "          b = array([[1], [0], [2], [1]])\n",
      "        \n",
      "        If A = qr such that q is orthonormal (which is always possible via\n",
      "        Gram-Schmidt), then ``x = inv(r) * (q.T) * b``.  (In numpy practice,\n",
      "        however, we simply use `lstsq`.)\n",
      "        \n",
      "        >>> A = np.array([[0, 1], [1, 1], [1, 1], [2, 1]])\n",
      "        >>> A\n",
      "        array([[0, 1],\n",
      "               [1, 1],\n",
      "               [1, 1],\n",
      "               [2, 1]])\n",
      "        >>> b = np.array([1, 0, 2, 1])\n",
      "        >>> q, r = np.linalg.qr(A)\n",
      "        >>> p = np.dot(q.T, b)\n",
      "        >>> np.dot(np.linalg.inv(r), p)\n",
      "        array([  1.1e-16,   1.0e+00])\n",
      "    \n",
      "    slogdet(a)\n",
      "        Compute the sign and (natural) logarithm of the determinant of an array.\n",
      "        \n",
      "        If an array has a very small or very large determinant, then a call to\n",
      "        `det` may overflow or underflow. This routine is more robust against such\n",
      "        issues, because it computes the logarithm of the determinant rather than\n",
      "        the determinant itself.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : (..., M, M) array_like\n",
      "            Input array, has to be a square 2-D array.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        sign : (...) array_like\n",
      "            A number representing the sign of the determinant. For a real matrix,\n",
      "            this is 1, 0, or -1. For a complex matrix, this is a complex number\n",
      "            with absolute value 1 (i.e., it is on the unit circle), or else 0.\n",
      "        logdet : (...) array_like\n",
      "            The natural log of the absolute value of the determinant.\n",
      "        \n",
      "        If the determinant is zero, then `sign` will be 0 and `logdet` will be\n",
      "        -Inf. In all cases, the determinant is equal to ``sign * np.exp(logdet)``.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        det\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        \n",
      "        .. versionadded:: 1.8.0\n",
      "        \n",
      "        Broadcasting rules apply, see the `numpy.linalg` documentation for\n",
      "        details.\n",
      "        \n",
      "        .. versionadded:: 1.6.0\n",
      "        \n",
      "        The determinant is computed via LU factorization using the LAPACK\n",
      "        routine ``z/dgetrf``.\n",
      "        \n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        The determinant of a 2-D array ``[[a, b], [c, d]]`` is ``ad - bc``:\n",
      "        \n",
      "        >>> a = np.array([[1, 2], [3, 4]])\n",
      "        >>> (sign, logdet) = np.linalg.slogdet(a)\n",
      "        >>> (sign, logdet)\n",
      "        (-1, 0.69314718055994529) # may vary\n",
      "        >>> sign * np.exp(logdet)\n",
      "        -2.0\n",
      "        \n",
      "        Computing log-determinants for a stack of matrices:\n",
      "        \n",
      "        >>> a = np.array([ [[1, 2], [3, 4]], [[1, 2], [2, 1]], [[1, 3], [3, 1]] ])\n",
      "        >>> a.shape\n",
      "        (3, 2, 2)\n",
      "        >>> sign, logdet = np.linalg.slogdet(a)\n",
      "        >>> (sign, logdet)\n",
      "        (array([-1., -1., -1.]), array([ 0.69314718,  1.09861229,  2.07944154]))\n",
      "        >>> sign * np.exp(logdet)\n",
      "        array([-2., -3., -8.])\n",
      "        \n",
      "        This routine succeeds where ordinary `det` does not:\n",
      "        \n",
      "        >>> np.linalg.det(np.eye(500) * 0.1)\n",
      "        0.0\n",
      "        >>> np.linalg.slogdet(np.eye(500) * 0.1)\n",
      "        (1, -1151.2925464970228)\n",
      "    \n",
      "    solve(a, b)\n",
      "        Solve a linear matrix equation, or system of linear scalar equations.\n",
      "        \n",
      "        Computes the \"exact\" solution, `x`, of the well-determined, i.e., full\n",
      "        rank, linear matrix equation `ax = b`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : (..., M, M) array_like\n",
      "            Coefficient matrix.\n",
      "        b : {(..., M,), (..., M, K)}, array_like\n",
      "            Ordinate or \"dependent variable\" values.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        x : {(..., M,), (..., M, K)} ndarray\n",
      "            Solution to the system a x = b.  Returned shape is identical to `b`.\n",
      "        \n",
      "        Raises\n",
      "        ------\n",
      "        LinAlgError\n",
      "            If `a` is singular or not square.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        scipy.linalg.solve : Similar function in SciPy.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        \n",
      "        .. versionadded:: 1.8.0\n",
      "        \n",
      "        Broadcasting rules apply, see the `numpy.linalg` documentation for\n",
      "        details.\n",
      "        \n",
      "        The solutions are computed using LAPACK routine ``_gesv``.\n",
      "        \n",
      "        `a` must be square and of full-rank, i.e., all rows (or, equivalently,\n",
      "        columns) must be linearly independent; if either is not true, use\n",
      "        `lstsq` for the least-squares best \"solution\" of the\n",
      "        system/equation.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] G. Strang, *Linear Algebra and Its Applications*, 2nd Ed., Orlando,\n",
      "               FL, Academic Press, Inc., 1980, pg. 22.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Solve the system of equations ``x0 + 2 * x1 = 1`` and ``3 * x0 + 5 * x1 = 2``:\n",
      "        \n",
      "        >>> a = np.array([[1, 2], [3, 5]])\n",
      "        >>> b = np.array([1, 2])\n",
      "        >>> x = np.linalg.solve(a, b)\n",
      "        >>> x\n",
      "        array([-1.,  1.])\n",
      "        \n",
      "        Check that the solution is correct:\n",
      "        \n",
      "        >>> np.allclose(np.dot(a, x), b)\n",
      "        True\n",
      "    \n",
      "    svd(a, full_matrices=True, compute_uv=True, hermitian=False)\n",
      "        Singular Value Decomposition.\n",
      "        \n",
      "        When `a` is a 2D array, it is factorized as ``u @ np.diag(s) @ vh\n",
      "        = (u * s) @ vh``, where `u` and `vh` are 2D unitary arrays and `s` is a 1D\n",
      "        array of `a`'s singular values. When `a` is higher-dimensional, SVD is\n",
      "        applied in stacked mode as explained below.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : (..., M, N) array_like\n",
      "            A real or complex array with ``a.ndim >= 2``.\n",
      "        full_matrices : bool, optional\n",
      "            If True (default), `u` and `vh` have the shapes ``(..., M, M)`` and\n",
      "            ``(..., N, N)``, respectively.  Otherwise, the shapes are\n",
      "            ``(..., M, K)`` and ``(..., K, N)``, respectively, where\n",
      "            ``K = min(M, N)``.\n",
      "        compute_uv : bool, optional\n",
      "            Whether or not to compute `u` and `vh` in addition to `s`.  True\n",
      "            by default.\n",
      "        hermitian : bool, optional\n",
      "            If True, `a` is assumed to be Hermitian (symmetric if real-valued),\n",
      "            enabling a more efficient method for finding singular values.\n",
      "            Defaults to False.\n",
      "        \n",
      "            .. versionadded:: 1.17.0\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        u : { (..., M, M), (..., M, K) } array\n",
      "            Unitary array(s). The first ``a.ndim - 2`` dimensions have the same\n",
      "            size as those of the input `a`. The size of the last two dimensions\n",
      "            depends on the value of `full_matrices`. Only returned when\n",
      "            `compute_uv` is True.\n",
      "        s : (..., K) array\n",
      "            Vector(s) with the singular values, within each vector sorted in\n",
      "            descending order. The first ``a.ndim - 2`` dimensions have the same\n",
      "            size as those of the input `a`.\n",
      "        vh : { (..., N, N), (..., K, N) } array\n",
      "            Unitary array(s). The first ``a.ndim - 2`` dimensions have the same\n",
      "            size as those of the input `a`. The size of the last two dimensions\n",
      "            depends on the value of `full_matrices`. Only returned when\n",
      "            `compute_uv` is True.\n",
      "        \n",
      "        Raises\n",
      "        ------\n",
      "        LinAlgError\n",
      "            If SVD computation does not converge.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        scipy.linalg.svd : Similar function in SciPy.\n",
      "        scipy.linalg.svdvals : Compute singular values of a matrix.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        \n",
      "        .. versionchanged:: 1.8.0\n",
      "           Broadcasting rules apply, see the `numpy.linalg` documentation for\n",
      "           details.\n",
      "        \n",
      "        The decomposition is performed using LAPACK routine ``_gesdd``.\n",
      "        \n",
      "        SVD is usually described for the factorization of a 2D matrix :math:`A`.\n",
      "        The higher-dimensional case will be discussed below. In the 2D case, SVD is\n",
      "        written as :math:`A = U S V^H`, where :math:`A = a`, :math:`U= u`,\n",
      "        :math:`S= \\mathtt{np.diag}(s)` and :math:`V^H = vh`. The 1D array `s`\n",
      "        contains the singular values of `a` and `u` and `vh` are unitary. The rows\n",
      "        of `vh` are the eigenvectors of :math:`A^H A` and the columns of `u` are\n",
      "        the eigenvectors of :math:`A A^H`. In both cases the corresponding\n",
      "        (possibly non-zero) eigenvalues are given by ``s**2``.\n",
      "        \n",
      "        If `a` has more than two dimensions, then broadcasting rules apply, as\n",
      "        explained in :ref:`routines.linalg-broadcasting`. This means that SVD is\n",
      "        working in \"stacked\" mode: it iterates over all indices of the first\n",
      "        ``a.ndim - 2`` dimensions and for each combination SVD is applied to the\n",
      "        last two indices. The matrix `a` can be reconstructed from the\n",
      "        decomposition with either ``(u * s[..., None, :]) @ vh`` or\n",
      "        ``u @ (s[..., None] * vh)``. (The ``@`` operator can be replaced by the\n",
      "        function ``np.matmul`` for python versions below 3.5.)\n",
      "        \n",
      "        If `a` is a ``matrix`` object (as opposed to an ``ndarray``), then so are\n",
      "        all the return values.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> a = np.random.randn(9, 6) + 1j*np.random.randn(9, 6)\n",
      "        >>> b = np.random.randn(2, 7, 8, 3) + 1j*np.random.randn(2, 7, 8, 3)\n",
      "        \n",
      "        Reconstruction based on full SVD, 2D case:\n",
      "        \n",
      "        >>> u, s, vh = np.linalg.svd(a, full_matrices=True)\n",
      "        >>> u.shape, s.shape, vh.shape\n",
      "        ((9, 9), (6,), (6, 6))\n",
      "        >>> np.allclose(a, np.dot(u[:, :6] * s, vh))\n",
      "        True\n",
      "        >>> smat = np.zeros((9, 6), dtype=complex)\n",
      "        >>> smat[:6, :6] = np.diag(s)\n",
      "        >>> np.allclose(a, np.dot(u, np.dot(smat, vh)))\n",
      "        True\n",
      "        \n",
      "        Reconstruction based on reduced SVD, 2D case:\n",
      "        \n",
      "        >>> u, s, vh = np.linalg.svd(a, full_matrices=False)\n",
      "        >>> u.shape, s.shape, vh.shape\n",
      "        ((9, 6), (6,), (6, 6))\n",
      "        >>> np.allclose(a, np.dot(u * s, vh))\n",
      "        True\n",
      "        >>> smat = np.diag(s)\n",
      "        >>> np.allclose(a, np.dot(u, np.dot(smat, vh)))\n",
      "        True\n",
      "        \n",
      "        Reconstruction based on full SVD, 4D case:\n",
      "        \n",
      "        >>> u, s, vh = np.linalg.svd(b, full_matrices=True)\n",
      "        >>> u.shape, s.shape, vh.shape\n",
      "        ((2, 7, 8, 8), (2, 7, 3), (2, 7, 3, 3))\n",
      "        >>> np.allclose(b, np.matmul(u[..., :3] * s[..., None, :], vh))\n",
      "        True\n",
      "        >>> np.allclose(b, np.matmul(u[..., :3], s[..., None] * vh))\n",
      "        True\n",
      "        \n",
      "        Reconstruction based on reduced SVD, 4D case:\n",
      "        \n",
      "        >>> u, s, vh = np.linalg.svd(b, full_matrices=False)\n",
      "        >>> u.shape, s.shape, vh.shape\n",
      "        ((2, 7, 8, 3), (2, 7, 3), (2, 7, 3, 3))\n",
      "        >>> np.allclose(b, np.matmul(u * s[..., None, :], vh))\n",
      "        True\n",
      "        >>> np.allclose(b, np.matmul(u, s[..., None] * vh))\n",
      "        True\n",
      "    \n",
      "    tensorinv(a, ind=2)\n",
      "        Compute the 'inverse' of an N-dimensional array.\n",
      "        \n",
      "        The result is an inverse for `a` relative to the tensordot operation\n",
      "        ``tensordot(a, b, ind)``, i. e., up to floating-point accuracy,\n",
      "        ``tensordot(tensorinv(a), a, ind)`` is the \"identity\" tensor for the\n",
      "        tensordot operation.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            Tensor to 'invert'. Its shape must be 'square', i. e.,\n",
      "            ``prod(a.shape[:ind]) == prod(a.shape[ind:])``.\n",
      "        ind : int, optional\n",
      "            Number of first indices that are involved in the inverse sum.\n",
      "            Must be a positive integer, default is 2.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        b : ndarray\n",
      "            `a`'s tensordot inverse, shape ``a.shape[ind:] + a.shape[:ind]``.\n",
      "        \n",
      "        Raises\n",
      "        ------\n",
      "        LinAlgError\n",
      "            If `a` is singular or not 'square' (in the above sense).\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        numpy.tensordot, tensorsolve\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> a = np.eye(4*6)\n",
      "        >>> a.shape = (4, 6, 8, 3)\n",
      "        >>> ainv = np.linalg.tensorinv(a, ind=2)\n",
      "        >>> ainv.shape\n",
      "        (8, 3, 4, 6)\n",
      "        >>> b = np.random.randn(4, 6)\n",
      "        >>> np.allclose(np.tensordot(ainv, b), np.linalg.tensorsolve(a, b))\n",
      "        True\n",
      "        \n",
      "        >>> a = np.eye(4*6)\n",
      "        >>> a.shape = (24, 8, 3)\n",
      "        >>> ainv = np.linalg.tensorinv(a, ind=1)\n",
      "        >>> ainv.shape\n",
      "        (8, 3, 24)\n",
      "        >>> b = np.random.randn(24)\n",
      "        >>> np.allclose(np.tensordot(ainv, b, 1), np.linalg.tensorsolve(a, b))\n",
      "        True\n",
      "    \n",
      "    tensorsolve(a, b, axes=None)\n",
      "        Solve the tensor equation ``a x = b`` for x.\n",
      "        \n",
      "        It is assumed that all indices of `x` are summed over in the product,\n",
      "        together with the rightmost indices of `a`, as is done in, for example,\n",
      "        ``tensordot(a, x, axes=b.ndim)``.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            Coefficient tensor, of shape ``b.shape + Q``. `Q`, a tuple, equals\n",
      "            the shape of that sub-tensor of `a` consisting of the appropriate\n",
      "            number of its rightmost indices, and must be such that\n",
      "            ``prod(Q) == prod(b.shape)`` (in which sense `a` is said to be\n",
      "            'square').\n",
      "        b : array_like\n",
      "            Right-hand tensor, which can be of any shape.\n",
      "        axes : tuple of ints, optional\n",
      "            Axes in `a` to reorder to the right, before inversion.\n",
      "            If None (default), no reordering is done.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        x : ndarray, shape Q\n",
      "        \n",
      "        Raises\n",
      "        ------\n",
      "        LinAlgError\n",
      "            If `a` is singular or not 'square' (in the above sense).\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        numpy.tensordot, tensorinv, numpy.einsum\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> a = np.eye(2*3*4)\n",
      "        >>> a.shape = (2*3, 4, 2, 3, 4)\n",
      "        >>> b = np.random.randn(2*3, 4)\n",
      "        >>> x = np.linalg.tensorsolve(a, b)\n",
      "        >>> x.shape\n",
      "        (2, 3, 4)\n",
      "        >>> np.allclose(np.tensordot(a, x, axes=3), b)\n",
      "        True\n",
      "\n",
      "DATA\n",
      "    __all__ = ['matrix_power', 'solve', 'tensorsolve', 'tensorinv', 'inv',...\n",
      "\n",
      "FILE\n",
      "    d:\\softwares\\anaconda\\lib\\site-packages\\numpy\\linalg\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# np.linalg documentation\n",
    "help(np.linalg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]]\n"
     ]
    }
   ],
   "source": [
    "# Creating arrays\n",
    "a = np.arange(1, 10).reshape(3, 3)\n",
    "b= np.arange(1, 13).reshape(3, 4)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.15251974e+15, -6.30503948e+15,  3.15251974e+15],\n",
       "       [-6.30503948e+15,  1.26100790e+16, -6.30503948e+15],\n",
       "       [ 3.15251974e+15, -6.30503948e+15,  3.15251974e+15]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inverse\n",
    "np.linalg.inv(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9.51619735392994e-16"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determinant\n",
    "np.linalg.det(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.61168440e+01, -1.11684397e+00, -9.75918483e-16]),\n",
       " array([[-0.23197069, -0.78583024,  0.40824829],\n",
       "        [-0.52532209, -0.08675134, -0.81649658],\n",
       "        [-0.8186735 ,  0.61232756,  0.40824829]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eigenvalues and eigenvectors\n",
    "np.linalg.eig(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 38,  44,  50,  56],\n",
       "       [ 83,  98, 113, 128],\n",
       "       [128, 152, 176, 200]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiply matrices\n",
    "np.dot(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.42528881 0.40657457 0.34164631 0.91217016]\n",
      " [0.71403532 0.03413834 0.42666704 0.53775728]\n",
      " [0.33927705 0.89720408 0.49237759 0.39872151]\n",
      " [0.37141594 0.42857114 0.48674924 0.95567864]]\n",
      "\n",
      "[[0.99016122 0.45640536 0.51764117 0.8950096  0.4607941  0.86869394\n",
      "  0.1802253 ]\n",
      " [0.23882228 0.13494693 0.56396152 0.34652317 0.62783537 0.09906281\n",
      "  0.45925911]\n",
      " [0.970964   0.61291739 0.39657619 0.13431738 0.50796839 0.67393927\n",
      "  0.42342808]\n",
      " [0.79058973 0.15532091 0.95483765 0.8118161  0.17539229 0.37728607\n",
      "  0.69763216]\n",
      " [0.86249985 0.3316584  0.41654502 0.55007373 0.2238746  0.25848376\n",
      "  0.5125277 ]]\n"
     ]
    }
   ],
   "source": [
    "m1 = np.random.rand(4,4)\n",
    "m2 = np.random.rand(5,7)\n",
    "print(m1)\n",
    "print()\n",
    "print(m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.78049138,  1.43583541,  0.42337654, -3.63848412],\n",
       "       [ 1.93321085, -0.70703799,  1.1949293 , -1.94589098],\n",
       "       [-6.57211399,  0.84094698,  0.21959491,  5.70809421],\n",
       "       [ 1.39977416, -0.66926931, -0.81224862,  0.4258055 ]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.inv(m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2.07119093+0.j        , -0.44619183+0.j        ,\n",
       "         0.14124214+0.20771187j,  0.14124214-0.20771187j]),\n",
       " array([[-0.5150631 +0.j        , -0.1213811 +0.j        ,\n",
       "         -0.41317104+0.20457401j, -0.41317104-0.20457401j],\n",
       "        [-0.42997827+0.j        ,  0.72967831+0.j        ,\n",
       "         -0.07397569+0.22084363j, -0.07397569-0.22084363j],\n",
       "        [-0.49455838+0.j        , -0.67160177+0.j        ,\n",
       "          0.79623596+0.j        ,  0.79623596-0.j        ],\n",
       "        [-0.55248593+0.j        ,  0.04227599+0.j        ,\n",
       "         -0.18317529-0.25622248j, -0.18317529+0.25622248j]]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.eig(m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.05830782041664099"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.det(m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (4,4) and (5,7) not aligned: 4 (dim 1) != 5 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3860\\3027020187.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (4,4) and (5,7) not aligned: 4 (dim 1) != 5 (dim 0)"
     ]
    }
   ],
   "source": [
    "np.dot(m1, m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.32996563 0.96431737 1.13203722 1.05347258 1.08625951 0.83273443]\n",
      " [0.8783824  0.7062268  1.01385947 0.79347462 0.93943754 0.82438905]\n",
      " [1.30332131 1.2024648  0.72966391 1.01526931 1.02408105 0.74638174]\n",
      " [1.5043924  1.04181246 1.13100414 1.22930048 1.16983303 0.8985078 ]]\n",
      "\n",
      "Shape is: (4, 6)\n"
     ]
    }
   ],
   "source": [
    "m3 = np.random.rand(4,6)\n",
    "m4= np.dot(m1,m3)\n",
    "print(m4)\n",
    "print()\n",
    "print('Shape is:', m4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.18087057 0.16530288 0.1167222  0.8320544 ]\n",
      " [0.50984644 0.00116543 0.18204476 0.2891829 ]\n",
      " [0.11510892 0.80497517 0.24243569 0.15897885]\n",
      " [0.1379498  0.18367322 0.23692482 0.91332166]]\n"
     ]
    }
   ],
   "source": [
    "print(m1*m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4864531  0.0431352  0.63217345]\n",
      " [0.88639858 0.29356583 0.9861039 ]\n",
      " [0.90957921 0.56680361 0.16976195]\n",
      " [0.68136181 0.45663306 0.63341502]]\n",
      "\n",
      "[0.90957921 0.56680361 0.16976195]\n"
     ]
    }
   ],
   "source": [
    "a = np.random.rand(4,3)\n",
    "print(a)\n",
    "print()\n",
    "print(a[2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 3 1]\n",
      " [5 7 0]\n",
      " [9 9 3]\n",
      " [8 2 4]]\n",
      "\n",
      "[4 3 1]\n",
      "\n",
      "[[4 3 1]\n",
      " [5 7 0]\n",
      " [4 3 1]\n",
      " [8 2 4]]\n",
      "\n",
      "[[4 3 1]\n",
      " [5 7 0]\n",
      " [4 3 1]\n",
      " [8 2 4]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[4, 3, 1], [5, 7, 0], [9, 9, 3], [8, 2, 4]])\n",
    "print(a)\n",
    "print()\n",
    "m,n = 0,2\n",
    "# Write your code for swapping here\n",
    "temp = a[m,:]\n",
    "print(temp)\n",
    "print()\n",
    "a[n,:] = a[m, :]\n",
    "print(a)\n",
    "print()\n",
    "a[m,:] = temp\n",
    "# Print the array after swapping\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.ndim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
